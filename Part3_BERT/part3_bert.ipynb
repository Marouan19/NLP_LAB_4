{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8525875,"sourceType":"datasetVersion","datasetId":5091235}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom transformers import BertModel, BertTokenizer\nimport json\nimport pandas as pd\nimport gzip\nfrom torch.utils.data import DataLoader, TensorDataset, random_split\nfrom transformers import BertTokenizer, BertForSequenceClassification","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import json\nimport pandas as pd\n\n# Load the dataset\ndata = []\nwith open('/kaggle/input/amazon-fashion/AMAZON_FASHION_5.json', 'r') as f:\n    for line in f:\n        data.append(json.loads(line))\n\ndf = pd.DataFrame(data)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:11:47.981887Z","iopub.execute_input":"2024-05-27T02:11:47.982699Z","iopub.status.idle":"2024-05-27T02:11:48.030059Z","shell.execute_reply.started":"2024-05-27T02:11:47.982670Z","shell.execute_reply":"2024-05-27T02:11:48.029314Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"df = df[df[\"reviewText\"].apply(lambda x: isinstance(x, str))]","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:11:56.597179Z","iopub.execute_input":"2024-05-27T02:11:56.597555Z","iopub.status.idle":"2024-05-27T02:11:56.605975Z","shell.execute_reply.started":"2024-05-27T02:11:56.597527Z","shell.execute_reply":"2024-05-27T02:11:56.605088Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:12:02.414199Z","iopub.execute_input":"2024-05-27T02:12:02.414540Z","iopub.status.idle":"2024-05-27T02:12:02.438660Z","shell.execute_reply.started":"2024-05-27T02:12:02.414513Z","shell.execute_reply":"2024-05-27T02:12:02.437558Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"      overall  verified   reviewTime      reviewerID        asin  \\\n0         5.0      True   09 4, 2015   ALJ66O1Y6SLHA  B000K2PJ4K   \n1         5.0      True   09 4, 2015   ALJ66O1Y6SLHA  B000K2PJ4K   \n2         5.0      True   09 4, 2015   ALJ66O1Y6SLHA  B000K2PJ4K   \n3         5.0      True   09 4, 2015   ALJ66O1Y6SLHA  B000K2PJ4K   \n4         5.0      True   09 4, 2015   ALJ66O1Y6SLHA  B000K2PJ4K   \n...       ...       ...          ...             ...         ...   \n3171      5.0      True   07 2, 2018  A2077NII5H62R2  B005AGO4LU   \n3172      5.0      True  06 28, 2018  A2IBS6PIPAGAB5  B005AGO4LU   \n3173      5.0      True  06 25, 2018  A1GTC5EVSJNCQ8  B005AGO4LU   \n3174      5.0      True  06 20, 2018  A311XHHLM12MUT  B005AGO4LU   \n3175      5.0      True  06 16, 2018  A135SGOQMVWABQ  B005AGO4LU   \n\n                                                  style     reviewerName  \\\n0      {'Size:': ' Big Boys', 'Color:': ' Blue/Orange'}         Tonya B.   \n1     {'Size:': ' Big Boys', 'Color:': ' Black (3746...         Tonya B.   \n2     {'Size:': ' Big Boys', 'Color:': ' Blue/Gray L...         Tonya B.   \n3     {'Size:': ' Big Boys', 'Color:': ' Blue (37867...         Tonya B.   \n4        {'Size:': ' Big Boys', 'Color:': ' Blue/Pink'}         Tonya B.   \n...                                                 ...              ...   \n3171  {'Size:': ' 8.5 B(M) US', 'Color:': ' Green Gl...  Amazon Customer   \n3172  {'Size:': ' 5 B(M) US', 'Color:': ' Wolf Grey/...         J. Avila   \n3173  {'Size:': ' 8 B(M) US', 'Color:': ' Blue Tint/...  Amazon Customer   \n3174  {'Size:': ' 9 B(M) US', 'Color:': ' Blue Tint/...            Peter   \n3175  {'Size:': ' 9 B(M) US', 'Color:': ' Black/Whit...            Susan   \n\n                                             reviewText      summary  \\\n0                              Great product and price!   Five Stars   \n1                              Great product and price!   Five Stars   \n2                              Great product and price!   Five Stars   \n3                              Great product and price!   Five Stars   \n4                              Great product and price!   Five Stars   \n...                                                 ...          ...   \n3171                                       Perfect fit!   Five Stars   \n3172                        My favorite cross trainers!  Comfortable   \n3173                              Love them fit perfect   Five Stars   \n3174  Favorite Nike shoe ever! The flex sole is exce...   Love them!   \n3175       I wear these everyday to work, the gym, etc.   Five Stars   \n\n      unixReviewTime vote image  \n0         1441324800  NaN   NaN  \n1         1441324800  NaN   NaN  \n2         1441324800  NaN   NaN  \n3         1441324800  NaN   NaN  \n4         1441324800  NaN   NaN  \n...              ...  ...   ...  \n3171      1530489600  NaN   NaN  \n3172      1530144000  NaN   NaN  \n3173      1529884800  NaN   NaN  \n3174      1529452800  NaN   NaN  \n3175      1529107200  NaN   NaN  \n\n[3160 rows x 12 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>overall</th>\n      <th>verified</th>\n      <th>reviewTime</th>\n      <th>reviewerID</th>\n      <th>asin</th>\n      <th>style</th>\n      <th>reviewerName</th>\n      <th>reviewText</th>\n      <th>summary</th>\n      <th>unixReviewTime</th>\n      <th>vote</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>09 4, 2015</td>\n      <td>ALJ66O1Y6SLHA</td>\n      <td>B000K2PJ4K</td>\n      <td>{'Size:': ' Big Boys', 'Color:': ' Blue/Orange'}</td>\n      <td>Tonya B.</td>\n      <td>Great product and price!</td>\n      <td>Five Stars</td>\n      <td>1441324800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>09 4, 2015</td>\n      <td>ALJ66O1Y6SLHA</td>\n      <td>B000K2PJ4K</td>\n      <td>{'Size:': ' Big Boys', 'Color:': ' Black (3746...</td>\n      <td>Tonya B.</td>\n      <td>Great product and price!</td>\n      <td>Five Stars</td>\n      <td>1441324800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>09 4, 2015</td>\n      <td>ALJ66O1Y6SLHA</td>\n      <td>B000K2PJ4K</td>\n      <td>{'Size:': ' Big Boys', 'Color:': ' Blue/Gray L...</td>\n      <td>Tonya B.</td>\n      <td>Great product and price!</td>\n      <td>Five Stars</td>\n      <td>1441324800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>09 4, 2015</td>\n      <td>ALJ66O1Y6SLHA</td>\n      <td>B000K2PJ4K</td>\n      <td>{'Size:': ' Big Boys', 'Color:': ' Blue (37867...</td>\n      <td>Tonya B.</td>\n      <td>Great product and price!</td>\n      <td>Five Stars</td>\n      <td>1441324800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>09 4, 2015</td>\n      <td>ALJ66O1Y6SLHA</td>\n      <td>B000K2PJ4K</td>\n      <td>{'Size:': ' Big Boys', 'Color:': ' Blue/Pink'}</td>\n      <td>Tonya B.</td>\n      <td>Great product and price!</td>\n      <td>Five Stars</td>\n      <td>1441324800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3171</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>07 2, 2018</td>\n      <td>A2077NII5H62R2</td>\n      <td>B005AGO4LU</td>\n      <td>{'Size:': ' 8.5 B(M) US', 'Color:': ' Green Gl...</td>\n      <td>Amazon Customer</td>\n      <td>Perfect fit!</td>\n      <td>Five Stars</td>\n      <td>1530489600</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3172</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>06 28, 2018</td>\n      <td>A2IBS6PIPAGAB5</td>\n      <td>B005AGO4LU</td>\n      <td>{'Size:': ' 5 B(M) US', 'Color:': ' Wolf Grey/...</td>\n      <td>J. Avila</td>\n      <td>My favorite cross trainers!</td>\n      <td>Comfortable</td>\n      <td>1530144000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3173</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>06 25, 2018</td>\n      <td>A1GTC5EVSJNCQ8</td>\n      <td>B005AGO4LU</td>\n      <td>{'Size:': ' 8 B(M) US', 'Color:': ' Blue Tint/...</td>\n      <td>Amazon Customer</td>\n      <td>Love them fit perfect</td>\n      <td>Five Stars</td>\n      <td>1529884800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3174</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>06 20, 2018</td>\n      <td>A311XHHLM12MUT</td>\n      <td>B005AGO4LU</td>\n      <td>{'Size:': ' 9 B(M) US', 'Color:': ' Blue Tint/...</td>\n      <td>Peter</td>\n      <td>Favorite Nike shoe ever! The flex sole is exce...</td>\n      <td>Love them!</td>\n      <td>1529452800</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3175</th>\n      <td>5.0</td>\n      <td>True</td>\n      <td>06 16, 2018</td>\n      <td>A135SGOQMVWABQ</td>\n      <td>B005AGO4LU</td>\n      <td>{'Size:': ' 9 B(M) US', 'Color:': ' Black/Whit...</td>\n      <td>Susan</td>\n      <td>I wear these everyday to work, the gym, etc.</td>\n      <td>Five Stars</td>\n      <td>1529107200</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>3160 rows × 12 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Initialize the tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Define a function to tokenize the text\ndef tokenize_texts(texts, max_length=128):\n    return tokenizer.batch_encode_plus(\n        texts,\n        max_length=max_length,\n        padding='max_length',\n        truncation=True,\n        return_tensors='pt'\n    )\n\ninput_texts = df[\"reviewText\"].tolist()\n\n# Tokenize the reviewText column\ntokens = tokenize_texts(input_texts)\n\ninput_ids = tokens['input_ids']\nattention_masks = tokens['attention_mask']\n\n# Convert labels to tensor\nlabels = torch.tensor(df['overall'].apply(lambda x: 1 if x >= 4 else 0).values)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:12:23.569038Z","iopub.execute_input":"2024-05-27T02:12:23.569844Z","iopub.status.idle":"2024-05-27T02:12:27.219008Z","shell.execute_reply.started":"2024-05-27T02:12:23.569814Z","shell.execute_reply":"2024-05-27T02:12:27.217967Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"missing_reviews = df['reviewText'].isnull().sum()\nprint(f\"Number of missing reviews: {missing_reviews}\")\n\n# Check for non-string types in the reviewText column\nnon_string_reviews = df[~df['reviewText'].apply(lambda x: isinstance(x, str))]\nprint(f\"Number of non-string reviews: {len(non_string_reviews)}\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:20:10.046940Z","iopub.execute_input":"2024-05-27T02:20:10.047295Z","iopub.status.idle":"2024-05-27T02:20:10.056473Z","shell.execute_reply.started":"2024-05-27T02:20:10.047266Z","shell.execute_reply":"2024-05-27T02:20:10.055485Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Number of missing reviews: 0\nNumber of non-string reviews: 0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the model\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Move the model to the appropriate device\nmodel.to(device)\n\n# Create a TensorDataset\ndataset = TensorDataset(input_ids, attention_masks, labels)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:21:14.124435Z","iopub.execute_input":"2024-05-27T02:21:14.125134Z","iopub.status.idle":"2024-05-27T02:21:14.578892Z","shell.execute_reply.started":"2024-05-27T02:21:14.125104Z","shell.execute_reply":"2024-05-27T02:21:14.578148Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the dataset into training and validation sets\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:21:23.556198Z","iopub.execute_input":"2024-05-27T02:21:23.556897Z","iopub.status.idle":"2024-05-27T02:21:23.561713Z","shell.execute_reply.started":"2024-05-27T02:21:23.556867Z","shell.execute_reply":"2024-05-27T02:21:23.560773Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"# Define the DataLoader for training and validation sets\nbatch_size = 32\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:21:36.058076Z","iopub.execute_input":"2024-05-27T02:21:36.058697Z","iopub.status.idle":"2024-05-27T02:21:36.063718Z","shell.execute_reply.started":"2024-05-27T02:21:36.058667Z","shell.execute_reply":"2024-05-27T02:21:36.062684Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Define the optimizer and the learning rate scheduler\noptimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n\n# Define the loss function\ncriterion = torch.nn.CrossEntropyLoss()\n\n# Training loop\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    for batch in train_dataloader:\n        # Load data to the appropriate device\n        batch_input_ids, batch_attention_masks, batch_labels = tuple(t.to(device) for t in batch)\n        \n        # Zero out gradients\n        optimizer.zero_grad()\n        \n        # Forward pass\n        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, labels=batch_labels)\n        \n        # Get the loss and logit scores\n        loss, logits = outputs.loss, outputs.logits\n        \n        # Backward pass\n        loss.backward()\n        \n        # Update parameters\n        optimizer.step()\n        \n        # Accumulate the total loss\n        total_loss += loss.item()\n    \n    # Average training loss for the epoch\n    avg_train_loss = total_loss / len(train_dataloader)\n    print(f'Epoch {epoch+1}/{num_epochs}, Average Training Loss: {avg_train_loss:.4f}')\n    \n    # Validation loop\n    model.eval()\n    val_loss = 0\n    val_correct = 0\n    with torch.no_grad():\n        for batch in val_dataloader:\n            batch_input_ids, batch_attention_masks, batch_labels = tuple(t.to(device) for t in batch)\n            outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks, labels=batch_labels)\n            loss, logits = outputs.loss, outputs.logits\n            val_loss += loss.item()\n            _, predicted = torch.max(logits, 1)\n            val_correct += (predicted == batch_labels).sum().item()\n    \n    # Average validation loss for the epoch\n    avg_val_loss = val_loss / len(val_dataloader)\n    val_accuracy = val_correct / len(val_dataset)\n    print(f'Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n\n# Evaluation metrics\nmodel.eval()\npredictions = []\ntrue_labels = []\nwith torch.no_grad():\n    for batch in val_dataloader:\n        batch_input_ids, batch_attention_masks, batch_labels = tuple(t.to(device) for t in batch)\n        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_masks)\n        logits = outputs.logits\n        _, predicted = torch.max(logits, 1)\n        predictions.extend(predicted.cpu().numpy())\n        true_labels.extend(batch_labels.cpu().numpy())\n\n# Calculate evaluation metrics\nfrom sklearn.metrics import accuracy_score, f1_score\naccuracy = accuracy_score(true_labels, predictions)\nf1 = f1_score(true_labels, predictions)\n\nprint(f'Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:22:37.909495Z","iopub.execute_input":"2024-05-27T02:22:37.909889Z","iopub.status.idle":"2024-05-27T02:25:26.988849Z","shell.execute_reply.started":"2024-05-27T02:22:37.909861Z","shell.execute_reply":"2024-05-27T02:25:26.987905Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Epoch 1/3, Average Training Loss: 0.1281\nEpoch 1/3, Validation Loss: 0.0177, Validation Accuracy: 0.9921\nEpoch 2/3, Average Training Loss: 0.0115\nEpoch 2/3, Validation Loss: 0.0166, Validation Accuracy: 0.9937\nEpoch 3/3, Average Training Loss: 0.0110\nEpoch 3/3, Validation Loss: 0.0150, Validation Accuracy: 0.9953\nAccuracy: 0.9953, F1 Score: 0.9972\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example test data\nexample_reviews = [\n    \"This product exceeded my expectations. I highly recommend it!\",\n    \"Very disappointed with the quality of this product. Would not buy again.\",\n    \"The color and fit of this shirt are perfect. I love it!\",\n    \"Terrible experience with this company. Will never purchase from them again.\",\n    \"The delivery was fast and the packaging was great. Very satisfied with my purchase.\"\n]\n\n# Tokenize the example reviews\nexample_tokens = tokenize_texts(example_reviews)\n\n# Extract input IDs and attention masks\nexample_input_ids = example_tokens['input_ids']\nexample_attention_masks = example_tokens['attention_mask']\n\n# Move the data to the appropriate device\nexample_input_ids = example_input_ids.to(device)\nexample_attention_masks = example_attention_masks.to(device)\n\n# Make predictions\nmodel.eval()\nwith torch.no_grad():\n    example_outputs = model(input_ids=example_input_ids, attention_mask=example_attention_masks)\n    example_logits = example_outputs.logits\n    _, example_predictions = torch.max(example_logits, 1)\n\n# Decode predictions\ndecoded_predictions = [\"Positive\" if pred.item() == 1 else \"Negative\" for pred in example_predictions]\n\n# Display results\nfor review, prediction in zip(example_reviews, decoded_predictions):\n    print(f\"Review: {review}\")\n    print(f\"Sentiment Prediction: {prediction}\")\n    print()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:25:36.209170Z","iopub.execute_input":"2024-05-27T02:25:36.209832Z","iopub.status.idle":"2024-05-27T02:25:36.276290Z","shell.execute_reply.started":"2024-05-27T02:25:36.209800Z","shell.execute_reply":"2024-05-27T02:25:36.275413Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Review: This product exceeded my expectations. I highly recommend it!\nSentiment Prediction: Positive\n\nReview: Very disappointed with the quality of this product. Would not buy again.\nSentiment Prediction: Negative\n\nReview: The color and fit of this shirt are perfect. I love it!\nSentiment Prediction: Positive\n\nReview: Terrible experience with this company. Will never purchase from them again.\nSentiment Prediction: Positive\n\nReview: The delivery was fast and the packaging was great. Very satisfied with my purchase.\nSentiment Prediction: Positive\n\n","output_type":"stream"}]}]}